{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hyeonvidia/CUSTOMISED-DETECTION/blob/main/validate_custom_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41a2253b",
      "metadata": {
        "id": "41a2253b"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0748156",
      "metadata": {
        "id": "d0748156"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolo_m4max_run/train_batch_max/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e7f3ac4",
      "metadata": {
        "id": "2e7f3ac4",
        "outputId": "f4280f94-2cc6-4349-f226-b8388d1615d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ultralytics 8.3.235 ğŸš€ Python-3.10.19 torch-2.10.0.dev20251203 CPU (Apple M4 Max)\n",
            "YOLOv9s summary (fused): 197 layers, 7,169,797 parameters, 0 gradients, 26.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.5 ms, read: 217.9Â±10.3 MB/s, size: 48.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/hyeonvidia/Project/AX-Device-1/valid/labels.cache... 7046 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 7046/7046 20.0Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 441/441 4.1s/it 30:18<4.1s\n",
            "                   all       7046      12405      0.917      0.938      0.958      0.777\n",
            "               ballpen        117        117          1      0.924      0.995      0.711\n",
            "                banner       6245      10956      0.924      0.941      0.976       0.92\n",
            "                 chair        403       1049      0.942      0.914       0.98       0.93\n",
            "            chopsticks          5          7      0.575      0.968      0.815      0.586\n",
            "                 knife        107        107          1      0.938      0.969      0.732\n",
            "                 spoon        115        115       0.98      0.983      0.985      0.818\n",
            "                 straw         54         54          1      0.899      0.985      0.742\n",
            "Speed: 0.3ms preprocess, 255.3ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
            "Results saved to \u001b[1m/Users/hyeonvidia/Project/runs/detect/val\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([    0.71112,     0.91982,     0.93027,     0.58553,     0.73236,      0.8181,     0.74216])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Validate the model\n",
        "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
        "metrics.box.map  # map50-95\n",
        "metrics.box.map50  # map50\n",
        "metrics.box.map75  # map75\n",
        "metrics.box.maps  # a list containing mAP50-95 for each category"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch-mps",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}